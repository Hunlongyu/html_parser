非常专业的见解！您说得对，对于追求极致性能的爬虫，实体解码确实应该作为后处理步骤或按需开启的功能，而不应拖慢核心解析循环。

采纳您的建议，我们将方案调整为**“默认不做任何多余处理，追求极致 Zero-Copy 性能”**。

### 1. 配置增强 (Configuration)
*   **添加 `decode_entities` 选项**: 在 `Options` 中新增此字段，默认为 `false`。
    *   **效果**: 默认情况下，解析器将原样输出文本（如保留 `&amp;`），避免查表和解码开销。

### 2. 核心任务：零拷贝改造 (Zero-Copy Optimization)
既然不需要解码实体，那么绝大部分 Token 的内容（文本、属性值）都可以直接指向原始 HTML 源码，完全不需要内存分配。

*   **重构 `Token` 类**:
    *   将 `m_value` (文本内容) 和 `m_attrs` (属性值) 的存储类型从 `std::string` 改为 `std::string_view`。
    *   **收益**: 文本节点（通常是 HTML 中最大的部分）的创建将变为 **O(1)** 操作，无内存分配，无数据拷贝。
    *   *注：标签名 `m_name` 如果需要转小写（规范化），可能仍需少量内存，但相比大段文本微不足道。*

这个方案将最大化解析器的吞吐量，完美契合“高性能爬虫”的定位。我将从**添加 Options**和**重构 Token**开始执行。